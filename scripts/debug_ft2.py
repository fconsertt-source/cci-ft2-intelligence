#!/usr/bin/env python3
"""Debugging helpers for FT2 files (refactored to use centralized logging).

This script is intentionally small utility code used by developers and QA.
It now uses `src.infrastructure.logging.get_logger` and `FT2Parser` when parsing CSV/TSV.
"""

import os
import sys
import csv
from pathlib import Path

# Add project root to path for src imports
sys.path.append(str(Path(__file__).parent.parent))

from src.infrastructure.logging import get_logger
from src.ft2_reader.parser.ft2_parser import FT2Parser

logger = get_logger(__name__)


def clean_bad_files():
    """Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ§Ø±ØºØ© Ø£Ùˆ Ø§Ù„ØªØ§Ù„ÙØ© Ù…Ù† data/input_ft2"""
    target_dir = "data/input_ft2"
    if not os.path.exists(target_dir):
        logger.warning("Ø§Ù„Ù…Ø¬Ù„Ø¯ %s ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.", target_dir)
        return

    logger.info("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙØ© ÙÙŠ %s", target_dir)

    removed_count = 0
    for file in os.listdir(target_dir):
        if not file.endswith('.txt'):
            continue

        filepath = os.path.join(target_dir, file)
        try:
            should_remove = False
            reason = ""

            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()

            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ§Ù„Ù
            if not content.strip():
                should_remove = True
                reason = "ÙØ§Ø±Øº ØªÙ…Ø§Ù…Ø§Ù‹"
            elif "Hist:" in content and "Date:" not in content:
                should_remove = True
                reason = "Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª (ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„)"

            if should_remove:
                os.remove(filepath)
                logger.info("ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù: %s (%s)", file, reason)
                removed_count += 1

        except Exception as e:
            logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ %s: %s", file, e)

    if removed_count == 0:
        logger.info("âœ¨ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª ØªØ§Ù„ÙØ©.")
    else:
        logger.info("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ %d Ù…Ù„Ù.", removed_count)

def debug_raw_files():
    """ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø§Ù… (TSV/CSV) ÙÙŠ data/input_raw"""
    input_dir = "data/input_raw"
    
    if not os.path.exists(input_dir):
        logger.warning("Ø§Ù„Ù…Ø¬Ù„Ø¯ %s ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.", input_dir)
        return

    logger.info("ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø§Ù… ÙÙŠ: %s", input_dir)

    files = [f for f in os.listdir(input_dir) if f.endswith(('.tsv', '.csv'))]
    if not files:
        logger.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª .tsv Ø£Ùˆ .csv.")
        logger.info("ğŸ’¡ ØªÙ„Ù…ÙŠØ­: Ø¬Ø±Ø¨ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ø£ÙˆÙ„Ø§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: python -m scripts.run_ft2_pipeline --generate-data")
        return

    for file in files:
        filepath = os.path.join(input_dir, file)
        logger.info("ğŸ“„ Ø§Ù„Ù…Ù„Ù: %s", file)
        logger.debug("%s", "-" * 30)

        try:
            # If CSV/TSV, try parsing using FT2Parser to get a quick health check
            entries = FT2Parser.parse_file(filepath)
            if not entries:
                logger.warning("âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù: %s", file)
                continue

            logger.info("ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª: %d", len(entries))
            logger.info("ğŸ“ Ø£ÙˆÙ„ 3 Ø¹ÙŠÙ†Ø§Øª:")
            for i, e in enumerate(entries[:3]):
                logger.info("  %d: device=%s ts=%s temp=%s", i+1, getattr(e, 'device_id', None), getattr(e, 'timestamp', None), getattr(e, 'temperature', None))

        except Exception as e:
            logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù %s: %s", file, e)

def debug_ft2_files():
    """ØªØµØ­ÙŠØ­ Ù…Ø´Ø§ÙƒÙ„ Ù…Ù„ÙØ§Øª FT2"""
    input_dir = "data/input_ft2"

    if not os.path.exists(input_dir):
        logger.warning("Ø§Ù„Ù…Ø¬Ù„Ø¯ %s ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.", input_dir)
        return

    for file in os.listdir(input_dir):
        filepath = os.path.join(input_dir, file)

        if file.endswith('.txt'):
            logger.info("ÙØ­Øµ Ø§Ù„Ù…Ù„Ù: %s", file)

            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()

                if not content.strip():
                    logger.warning("âš ï¸  Ø§Ù„Ù…Ù„Ù ÙØ§Ø±Øº ØªÙ…Ø§Ù…Ø§Ù‹: %s", file)
                else:
                    lines = content.split('\n')
                    logger.info("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø·Ø±: %d", len(lines))
                    for i, line in enumerate(lines[:5]):
                        logger.debug("Ø³Ø·Ø± %d: %s", i+1, line[:100])

                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
                    keywords = ['Hist:', 'Date:', 'Min T:', 'Serial:']
                    for kw in keywords:
                        if kw in content:
                            logger.info("âœ… ÙˆØ¬Ø¯: %s", kw)
                        else:
                            logger.info("âŒ Ù„Ù… ÙŠØ¬Ø¯: %s", kw)
            except Exception as e:
                logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ %s: %s", file, e)

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--clean":
        clean_bad_files()
    else:
        debug_raw_files()
        debug_ft2_files()
        logger.info("\nğŸ’¡ ØªÙ„Ù…ÙŠØ­: Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ØŒ Ø´ØºÙ‘Ù„: python scripts/debug_ft2.py --clean")
